## 编码絮絮念

​		笔者不才作为学习者在学习python的道路上遇到过些些许许的小问题，愿在此记录下来若能帮助到其他人甚感荣幸。最初学习python的时候是从爬虫学起的，其次工作后在学习NLP相关内容，因此会经常接触数据（文本）的获取和保存，以及加上中文以外的各种语言。

# encoding

```python
my_text = "今天又是一周的开始，打起精神认真赚钱不含参"

with open("path", "w", encoding="utf-8") as f:
    f.write(my_text)
```

​		写入数据的时候最好是指定一下文件的编码方式，不然下次读取的时候可能就读取不了了（出现乱码）。经常遇到的问题是中文的保存，会以各种各样的编码方式保存。但其实在读取的时候选择对应的编码方式仍旧可以打开但直接保存为utf-8一劳永逸。特别是使用pandas将含有中文数据的DataFrame对象保存为csv文件的时候，有一个具体的编码方式需要指定。

​		其次如果是爬取的图片类型的数据此时的写入方式就需要更改为二进制方式保存，也是之前困扰过的问题。

​		如果爬取的文本中含有emoji而且准备写入mysql中，需要更改mysql数据库的编码方式为utf-8mb4格式，不然会出现问题。mysql数据库的版本也有要求具体5.10以上应该都可以~

​		数据的存写最好是使用with open() as f这种形式，上下文管理器会自动帮你读取完数据后关闭文件。不然在报错后寻找问题的原因真的很麻烦，一个小问题可能要找很久也找不到（亲生经历）。

​		如果遇到一个不确定是什么编码方式的文档，最好的方式是以txt打开该文件可以看到文件的编码方式，此时也可以另存为的时候将编码方式改为自己需要的合适的编码方式。

​		大文件的读写，很浪费时间而且对于内存的负担也很大。此时可以对数据进行分页读取比较合适 内存毕竟有限。pickle，和json可以将数据存储为二进制文件和通用的json格式文件。可能需要注意的地方就是dump和dunps以及load和loads的区别。这个真的是一直没注意每次都随机试，反正只最多需要试两下就可以，多试几次就知道了。pickle保存的.pkl文件内存小，读取快。真的非常和，json文件的引号需要注意一下。还有就是json文件load的时候如果数据有问题就直接写正则对数据做拆分，避免所有数据都被丢失。之前遇到过json文件保存明明可以，但是读取就是失败的问题。后来发现是有一些字符编码有问题，会具体报错的那个位置，可以自行定位一点一点的排除。网上有一个解决思路是有一个参数，控制解码相关的设置一下就可以了，但并不是万能的至少没解决我之前遇到的问题。

数据的写入读取方式：只读，只写，覆盖写等这些容易忽略很容易将幸幸苦苦的数据保存出问题然后发现结果不对劲。回头一看才发现是数据的写入有问题，这样就很消磨热情以及浪费时间。





----

解决问题的思路：

​		我不是计算机专业的，周围认识的人也没有学编程的。因此每当我遇到问题的时候就借助baidu，csdn，博客园这些。现在最主要还是谷歌要用的多，百度最差其次csdn总是跳来跳去也找不到答案，博客园如果有答案的话内容感觉还可以csdn挑来挑去没找到解决办法很烦人不过也好用。谷歌报错代码挺方便的，容易检索出来比较相似的问题。

更多的时候自己多试几下就能发现问题的原因，记得也更清楚一些。而且每当一个困扰很久的问题解决后的那种成就感真的很爽，有一种如释负重的感觉。

